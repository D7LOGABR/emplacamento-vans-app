import streamlit as st
import pandas as pd
import plotly.express as px
from dateutil.relativedelta import relativedelta
from collections import Counter
import os
import numpy as np
from io import BytesIO

# --- Configura√ß√£o da P√°gina ---
st.set_page_config(
    page_title="Emplacamentos VANS De Nigris",
    page_icon="üöö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Estilo CSS Customizado ---
st.markdown("""
<style>
    /* Ajustar padding do container principal */
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
        padding-left: 3rem;
        padding-right: 3rem;
    }
    /* Estilo para os cards de informa√ß√£o */
    .info-card {
        background-color: #f8f9fa;
        border-radius: 8px;
        padding: 15px;
        margin-bottom: 10px;
        border-left: 5px solid #0055a4; /* Azul De Nigris */
    }
    .info-card .label {
        font-weight: bold;
        color: #003366; /* Azul escuro De Nigris */
        display: block;
        margin-bottom: 3px;
    }
    .info-card .value {
        color: #333;
    }
    /* T√≠tulos */
    h1, h2, h3, h4 {
        color: #003366; /* Azul escuro De Nigris */
    }
    /* Bot√£o de busca */
    .stButton>button {
        background-color: #0055a4; /* Azul De Nigris */
        color: white;
        border-radius: 5px;
        padding: 0.5rem 1rem;
    }
    .stButton>button:hover {
        background-color: #003366;
        color: white;
    }
    /* Mensagens de erro/info */
    .stAlert p {
        font-size: 1rem; /* Ajustar tamanho da fonte nas mensagens */
    }
    /* Estilo para m√©tricas de resumo */
    .stMetric {
        background-color: #e9ecef;
        border-radius: 8px;
        padding: 10px 15px;
        border-left: 5px solid #6c757d; /* Cinza */
    }
</style>
""", unsafe_allow_html=True)

# --- Constantes e Caminhos ---
DATA_DIR = "data"
DEFAULT_EXCEL_FILE = os.path.join(DATA_DIR, "EMPLACAMENTO ANUAL - VANS.xlsx")
LOGO_COLOR_PATH = os.path.join(DATA_DIR, "logo_denigris_colorido.png")
LOGO_WHITE_PATH = os.path.join(DATA_DIR, "logo_denigris_branco.png")

# --- Nomes das Colunas Opcionais (Definidos Globalmente) ---
# Certifique-se que estes nomes correspondem EXATAMENTE aos da sua planilha
NOME_COLUNA_ENDERECO = "ENDERE√áO COMPLETO"
NOME_COLUNA_TELEFONE = "TELEFONE1" # <--- IMPORTANTE: Verifique e ajuste se necess√°rio!

# --- Fun√ß√µes de Carregamento de Dados ---
@st.cache_data(ttl=3600) # Cache por 1 hora para evitar recarregamentos constantes
def load_data(file_path_or_buffer):
    """Carrega e pr√©-processa os dados do arquivo Excel."""
    try:
        df = pd.read_excel(file_path_or_buffer)

        # Verificar se o DataFrame est√° vazio
        if df.empty:
            st.error("O arquivo Excel n√£o cont√©m dados.")
            return None

        # Garantir que colunas essenciais para an√°lise existam
        essential_cols = ["Marca", "Segmento", "NO_CIDADE", "Data emplacamento", "CNPJ CLIENTE", "NOME DO CLIENTE"]
        missing_cols = [col for col in essential_cols if col not in df.columns]
        if missing_cols:
            st.error(f"Erro: Colunas essenciais n√£o encontradas no arquivo Excel: {", ".join(missing_cols)}")
            return None

        # Limpeza e convers√£o de tipos (com dayfirst=True)
        df["Data emplacamento"] = pd.to_datetime(df["Data emplacamento"], errors="coerce", dayfirst=True)
        df["CNPJ CLIENTE"] = df["CNPJ CLIENTE"].astype(str).str.strip()
        df["NOME DO CLIENTE"] = df["NOME DO CLIENTE"].astype(str).str.strip()

        # Processar colunas opcionais usando nomes globais
        if NOME_COLUNA_ENDERECO in df.columns:
            df[NOME_COLUNA_ENDERECO] = df[NOME_COLUNA_ENDERECO].astype(str).str.strip()
        else:
            df[NOME_COLUNA_ENDERECO] = "N/A"

        if NOME_COLUNA_TELEFONE in df.columns:
            df[NOME_COLUNA_TELEFONE] = df[NOME_COLUNA_TELEFONE].astype(str).str.strip()
        else:
            df[NOME_COLUNA_TELEFONE] = "N/A"

        # Normalizar CNPJ
        df["CNPJ_NORMALIZED"] = df["CNPJ CLIENTE"].str.replace(r"[.\\/-]", "", regex=True)
        
        # Remover linhas onde datas ou colunas essenciais s√£o inv√°lidas
        # Primeiro, remover linhas com data de emplacamento inv√°lida
        df = df.dropna(subset=["Data emplacamento"])
        
        # Extrair ano e m√™s com tratamento seguro para NaN
        df["Ano"] = df["Data emplacamento"].dt.year
        df["Mes"] = df["Data emplacamento"].dt.month
        
        # Tratar valores NaN em Ano e Mes antes de converter para int
        # Remover linhas com Ano ou Mes inv√°lidos
        df = df.dropna(subset=["Ano", "Mes"])
        
        # Converter para int com seguran√ßa
        df["Ano"] = df["Ano"].astype(int)
        df["Mes"] = df["Mes"].astype(int)
        
        # Criar AnoMesStr com seguran√ßa (apenas para linhas com data v√°lida)
        df["AnoMesStr"] = df["Data emplacamento"].dt.strftime("%Y-%m")
        
        # Criar AnoMesNum com seguran√ßa
        # Primeiro criar uma string tempor√°ria e depois converter para int
        df["AnoMesTemp"] = df["Ano"].astype(str) + df["Mes"].apply(lambda x: f"{x:02d}")
        df["AnoMesNum"] = df["AnoMesTemp"].astype(int)
        df = df.drop(columns=["AnoMesTemp"])  # Remover coluna tempor√°ria
        
        # Remover linhas onde outras colunas essenciais s√£o inv√°lidas
        df = df.dropna(subset=["Marca", "Segmento", "NO_CIDADE", "CNPJ CLIENTE", "NOME DO CLIENTE"])
        
        # Verificar se ainda temos dados ap√≥s a limpeza
        if df.empty:
            st.error("Ap√≥s remover linhas com dados inv√°lidos, n√£o restaram registros para an√°lise.")
            return None
            
        return df
    except FileNotFoundError:
        st.error(f"Erro: Arquivo Excel padr√£o n√£o encontrado em {DEFAULT_EXCEL_FILE}. Fa√ßa o upload de um arquivo.")
        return None
    except Exception as e:
        file_info = "arquivo carregado" if isinstance(file_path_or_buffer, BytesIO) else os.path.basename(str(file_path_or_buffer))
        st.error(f"Erro ao carregar ou processar o arquivo Excel ({file_info}): {e}")
        return None

# --- Fun√ß√µes Auxiliares ---
def get_modes(series):
    cleaned_series = series.dropna().astype(str)
    if cleaned_series.empty:
        return ["N/A"]
    counts = Counter(cleaned_series)
    if not counts:
        return ["N/A"]
    max_count = counts.most_common(1)[0][1]
    modes = sorted([item for item, count in counts.items() if count == max_count])
    return modes

def format_list(items):
    if not items or items == ["N/A"]:
        return "N/A"
    return ", ".join(map(str, items))

def calculate_next_purchase_prediction(valid_purchase_dates):
    if not valid_purchase_dates or len(valid_purchase_dates) < 2:
        return "Previs√£o n√£o dispon√≠vel (hist√≥rico insuficiente).", None

    valid_purchase_dates.sort()
    last_purchase_date = valid_purchase_dates[-1]
    intervals_months = []
    for i in range(1, len(valid_purchase_dates)):
        delta = relativedelta(valid_purchase_dates[i], valid_purchase_dates[i-1])
        months_diff = delta.years * 12 + delta.months
        days_diff = delta.days
        # Considerar intervalo m√≠nimo de 1 m√™s, mesmo que dias sejam > 0
        if months_diff > 0:
            intervals_months.append(months_diff)
        elif months_diff == 0 and days_diff > 15: # Se mais de 15 dias, conta como ~0.5 m√™s
             intervals_months.append(0.5)
        # Ignorar intervalos muito curtos (menos de 15 dias)

    if not intervals_months:
         return "Previs√£o n√£o dispon√≠vel (compras muito pr√≥ximas ou √∫nica).", last_purchase_date

    avg_interval_months = sum(intervals_months) / len(intervals_months)
    # Definir um intervalo m√≠nimo razo√°vel (ex: 1 m√™s)
    avg_interval_months = max(1, avg_interval_months)

    predicted_next_date = last_purchase_date + relativedelta(months=int(round(avg_interval_months)))

    meses = ["Janeiro", "Fevereiro", "Mar√ßo", "Abril", "Maio", "Junho", "Julho", "Agosto", "Setembro", "Outubro", "Novembro", "Dezembro"]
    predicted_month_year = f"{meses[predicted_next_date.month - 1]} de {predicted_next_date.year}"
    prediction_text = f"Pr√≥xima compra prov√°vel em: **{predicted_month_year}** (intervalo m√©dio: {avg_interval_months:.1f} meses)"

    return prediction_text, predicted_next_date

def get_sales_pitch(last_purchase_date, predicted_next_date, total_purchases):
    today = pd.Timestamp.now().normalize()
    if not last_purchase_date:
        return "Primeira vez? ü§î Sem hist√≥rico de compras registrado para este cliente."

    if not isinstance(last_purchase_date, pd.Timestamp):
        last_purchase_date = pd.to_datetime(last_purchase_date)

    months_since_last = relativedelta(today, last_purchase_date).years * 12 + relativedelta(today, last_purchase_date).months
    last_purchase_str = last_purchase_date.strftime("%d/%m/%Y")

    if predicted_next_date and isinstance(predicted_next_date, pd.Timestamp):
        months_to_next = relativedelta(predicted_next_date, today).years * 12 + relativedelta(predicted_next_date, today).months
        days_to_next = relativedelta(predicted_next_date, today).days
        predicted_month_year = f"{["Janeiro", "Fevereiro", "Mar√ßo", "Abril", "Maio", "Junho", "Julho", "Agosto", "Setembro", "Outubro", "Novembro", "Dezembro"][predicted_next_date.month - 1]} de {predicted_next_date.year}"

        if months_to_next < 0 or (months_to_next == 0 and days_to_next < -7): # J√° passou h√° mais de uma semana
            return f"üö® **Aten√ß√£o!** A compra prevista para **{predicted_month_year}** pode ter passado! √öltima compra em {last_purchase_str}. Contato urgente!"
        elif months_to_next <= 1 and days_to_next >= -7: # Pr√≥ximo m√™s ou j√° passou h√° poucos dias
            return f"üìà **Oportunidade Quente!** Pr√≥xima compra prevista para **{predicted_month_year}**. √ìtimo momento para contato! √öltima compra em {last_purchase_str}."
        elif months_to_next <= 3:
            return f"üóìÔ∏è **Planeje-se!** Pr√≥xima compra prevista para **{predicted_month_year}**. Prepare sua abordagem! √öltima compra em {last_purchase_str}."
        else:
            return f"‚è≥ Compra prevista para **{predicted_month_year}**. Mantenha o relacionamento aquecido! √öltima compra em {last_purchase_str}."
    else:
        # Sem previs√£o, usar tempo desde a √∫ltima compra
        if months_since_last >= 18:
            return f"üö® Alerta de inatividade! Faz {months_since_last} meses desde a √∫ltima compra ({last_purchase_str}). Hora de reativar esse cliente! üìû"
        elif months_since_last >= 12:
            return f"üëÄ Faz {months_since_last} meses desde a √∫ltima compra ({last_purchase_str}). Que tal um contato para mostrar novidades?"
        elif months_since_last >= 6:
            return f"‚è≥ J√° se passaram {months_since_last} meses ({last_purchase_str}). Bom momento para um follow-up."
        elif total_purchases > 3:
             return f"üëç Cliente fiel ({total_purchases} compras)! √öltima compra em {last_purchase_str}. Mantenha o bom trabalho!"
        else:
            return f"‚úÖ Compra recente ({last_purchase_str}). √ìtimo para fortalecer o relacionamento!"

# --- Gerenciamento de Estado e Carregamento de Dados ---

# Inicializar estado da sess√£o se necess√°rio
if "df_loaded" not in st.session_state:
    st.session_state.df_loaded = None # Armazena o DataFrame carregado
if "data_source_key" not in st.session_state:
    st.session_state.data_source_key = None # Chave para identificar a fonte (default ou upload)
if "last_upload_info" not in st.session_state:
    st.session_state.last_upload_info = None # Guarda nome e tamanho do √∫ltimo upload

st.sidebar.header("Atualizar Dados")
uploaded_file = st.sidebar.file_uploader("Selecione o arquivo Excel (.xlsx)", type=["xlsx"], key="file_uploader")

load_from_default = False
load_from_upload = False

# L√≥gica de decis√£o para carregar/recarregar dados
if uploaded_file is not None:
    # Novo upload detectado
    current_upload_info = (uploaded_file.name, uploaded_file.size)
    if current_upload_info != st.session_state.last_upload_info:
        # √â um arquivo diferente do √∫ltimo upload ou o primeiro upload
        load_from_upload = True
        st.session_state.last_upload_info = current_upload_info
        st.sidebar.info(f"Arquivo 	'{uploaded_file.name}'	 selecionado.")
    elif st.session_state.df_loaded is None:
        # Mesmo arquivo, mas DataFrame n√£o est√° carregado (ex: ap√≥s erro)
        load_from_upload = True
elif st.session_state.df_loaded is None:
    # Nenhum upload ativo e nenhum DataFrame carregado, tentar carregar do default
    load_from_default = True

# Executar o carregamento se necess√°rio
data_loaded_successfully = False
if load_from_upload:
    try:
        uploaded_content = BytesIO(uploaded_file.getvalue())
        st.session_state.df_loaded = load_data(uploaded_content)
        if st.session_state.df_loaded is not None:
            st.session_state.data_source_key = f"upload_{uploaded_file.name}_{uploaded_file.size}"
            st.sidebar.success("Dados do arquivo carregado!")
            data_loaded_successfully = True
            st.rerun() # For√ßa recarregar a UI com os novos dados
        else:
            st.session_state.data_source_key = None # Falha no carregamento
            st.session_state.last_upload_info = None # Resetar info do upload
    except Exception as e:
        st.sidebar.error(f"Erro ao processar upload: {e}")
        st.session_state.df_loaded = None
        st.session_state.data_source_key = None
        st.session_state.last_upload_info = None

elif load_from_default:
    if os.path.exists(DEFAULT_EXCEL_FILE):
        try:
            st.session_state.df_loaded = load_data(DEFAULT_EXCEL_FILE)
            if st.session_state.df_loaded is not None:
                st.session_state.data_source_key = "default"
                st.sidebar.info(f"Usando arquivo padr√£o: {os.path.basename(DEFAULT_EXCEL_FILE)}")
                data_loaded_successfully = True
                # N√£o precisa de rerun aqui, pois √© o carregamento inicial
            else:
                st.session_state.data_source_key = None # Falha no carregamento
        except Exception as e:
            st.sidebar.error(f"Erro ao carregar arquivo padr√£o: {e}")
            st.session_state.df_loaded = None
            st.session_state.data_source_key = None
    else:
        st.sidebar.warning(f"Arquivo padr√£o n√£o encontrado em {DEFAULT_EXCEL_FILE}. Fa√ßa upload de um arquivo.")
        st.session_state.df_loaded = None
        st.session_state.data_source_key = None

# Verificar se temos um DataFrame para trabalhar
df_full = st.session_state.get("df_loaded")

if df_full is None or df_full.empty:
    st.warning("Nenhum dado carregado. Fa√ßa o upload de um arquivo Excel ou verifique o arquivo padr√£o.")
    st.stop() # Interrompe a execu√ß√£o se n√£o houver dados

# --- Interface Principal --- 

# --- Cabe√ßalho ---
col1_header, col2_header = st.columns([1, 3])
with col1_header:
    if os.path.exists(LOGO_COLOR_PATH):
        st.image(LOGO_COLOR_PATH, width=250)
    else:
        st.warning("Logo colorido n√£o encontrado.")
with col2_header:
    st.title("Consulta de Emplacamentos - VANS")
    st.markdown("**Ferramenta interna De Nigris** - Busque por cliente ou veja o resumo geral.")

st.divider()

# --- Barra de Busca e Filtros (MOVIMENTADO PARA CIMA) --- 
st.subheader("Buscar Cliente Espec√≠fico")
search_query = st.text_input("Digite o Nome ou CNPJ do cliente:", "", key="search_input")
search_button = st.button("Buscar", key="search_button")

st.sidebar.header("Filtros Gerais (Afetam Busca e Resumo)")
all_brands = sorted(df_full["Marca"].dropna().unique())
selected_brands = st.sidebar.multiselect("Filtrar por Marca:", all_brands, key="brand_filter")

all_segments = sorted(df_full["Segmento"].dropna().unique())
selected_segments = st.sidebar.multiselect("Filtrar por Segmento:", all_segments, key="segment_filter")

# Aplicar filtros ao DataFrame principal ANTES de qualquer c√°lculo
df_display = df_full.copy()
if selected_brands:
    df_display = df_display[df_display["Marca"].isin(selected_brands)]
if selected_segments:
    df_display = df_display[df_display["Segmento"].isin(selected_segments)]

# --- Exibi√ß√£o dos Resultados da Busca ou Resumo Geral --- 
st.divider()

if search_button and search_query:
    # --- Resultados da Busca Espec√≠fica ---
    st.markdown(f"### Resultados da Busca por: 	'{search_query}'")
    query_normalized = 	''.join(filter(str.isdigit, str(search_query)))

    mask = (
        df_display["NOME DO CLIENTE"].str.contains(search_query, case=False, na=False)
    )
    # S√≥ busca por CNPJ normalizado se a query tiver d√≠gitos
    if query_normalized:
         mask = mask | df_display["CNPJ_NORMALIZED"].str.contains(query_normalized, case=False, na=False)

    results_df = df_display[mask]

    if results_df.empty:
        st.warning("Cliente n√£o encontrado na base de dados (considerando os filtros aplicados, se houver).")
    else:
        unique_cnpjs = results_df["CNPJ_NORMALIZED"].unique()

        if len(unique_cnpjs) > 1:
            # Se m√∫ltiplos CNPJs, pegar o primeiro como refer√™ncia (pode precisar de l√≥gica mais sofisticada)
            target_cnpj_normalized = unique_cnpjs[0]
            first_match_name = results_df[results_df["CNPJ_NORMALIZED"] == target_cnpj_normalized]["NOME DO CLIENTE"].iloc[0]
            first_match_cnpj = results_df[results_df["CNPJ_NORMALIZED"] == target_cnpj_normalized]["CNPJ CLIENTE"].iloc[0]
            st.info(f"M√∫ltiplos clientes encontrados para \"{search_query}\". Exibindo resultados para: **{first_match_name} ({first_match_cnpj})**.")
        elif len(unique_cnpjs) == 1:
            target_cnpj_normalized = unique_cnpjs[0]
        else:
             # Caso estranho: m√°scara funcionou mas n√£o achou CNPJ (n√£o deveria acontecer com dropna)
             st.warning("N√£o foi poss√≠vel identificar um CNPJ √∫nico para o cliente.")
             st.stop()

        # Filtrar DataFrame para o CNPJ alvo
        client_df = df_display[df_display["CNPJ_NORMALIZED"] == target_cnpj_normalized].copy()

        if not client_df.empty:
            client_df_sorted = client_df.sort_values(by="Data emplacamento", ascending=False)
            latest_record = client_df_sorted.iloc[0]

            # Informa√ß√µes b√°sicas do cliente
            client_name = latest_record["NOME DO CLIENTE"]
            client_cnpj_formatted = latest_record["CNPJ CLIENTE"]
            client_address = latest_record.get(NOME_COLUNA_ENDERECO, "N/A")
            client_phone = latest_record.get(NOME_COLUNA_TELEFONE, "N/A")
            client_city = latest_record.get("NO_CIDADE", "N/A")

            st.subheader(f"Detalhes de: {client_name}")
            col1_info, col2_info = st.columns(2)
            with col1_info:
                st.markdown(f"<div class='info-card'><span class='label'>CNPJ:</span><span class='value'>{client_cnpj_formatted}</span></div>", unsafe_allow_html=True)
                st.markdown(f"<div class='info-card'><span class='label'>Endere√ßo:</span><span class='value'>{client_address}</span></div>", unsafe_allow_html=True)
            with col2_info:
                st.markdown(f"<div class='info-card'><span class='label'>Cidade:</span><span class='value'>{client_city}</span></div>", unsafe_allow_html=True)
                st.markdown(f"<div class='info-card'><span class='label'>Telefone:</span><span class='value'>{client_phone}</span></div>", unsafe_allow_html=True)

            st.markdown("#### An√°lise e Hist√≥rico")

            # C√°lculos para an√°lise
            total_purchases = len(client_df_sorted)
            first_purchase_date = client_df_sorted["Data emplacamento"].min()
            last_purchase_date = client_df_sorted["Data emplacamento"].max()
            valid_purchase_dates = client_df_sorted["Data emplacamento"].dropna().tolist()

            # Calcular previs√£o e pitch
            prediction_text, predicted_next_date = calculate_next_purchase_prediction(valid_purchase_dates)
            sales_pitch = get_sales_pitch(last_purchase_date, predicted_next_date, total_purchases)

            # Exibir Insight e Previs√£o (MOVIMENTADO PARA CIMA)
            col1_insight, col2_predict = st.columns(2)
            with col1_insight:
                 st.markdown(f"**Insight de Vendas:**")
                 st.info(sales_pitch)
            with col2_predict:
                 st.markdown(f"**Previs√£o de Pr√≥xima Compra:**")
                 st.info(prediction_text)

            # M√©tricas Resumidas do Cliente
            col1_metric, col2_metric, col3_metric = st.columns(3)
            col1_metric.metric("Total de Emplacamentos", total_purchases)
            col2_metric.metric("Primeira Compra", first_purchase_date.strftime("%d/%m/%Y") if pd.notna(first_purchase_date) else "N/A")
            col3_metric.metric("√öltima Compra", last_purchase_date.strftime("%d/%m/%Y") if pd.notna(last_purchase_date) else "N/A")

            # Hist√≥rico de Compras
            st.markdown("##### Hist√≥rico de Emplacamentos")
            client_df_display = client_df_sorted[["Data emplacamento", "Marca", "Modelo", "Segmento"]].rename(columns={
                "Data emplacamento": "Data",
                "Marca": "Marca",
                "Modelo": "Modelo",
                "Segmento": "Segmento"
            })
            client_df_display["Data"] = client_df_display["Data"].dt.strftime("%d/%m/%Y")
            st.dataframe(client_df_display, use_container_width=True)

            # Gr√°fico de Frequ√™ncia de Compra
            if total_purchases > 1:
                st.markdown("##### Frequ√™ncia de Compra (por M√™s/Ano)")
                purchase_frequency = client_df_sorted.groupby("AnoMesStr").size().reset_index(name="Count")
                # Garantir que AnoMesNum existe e √© int antes de ordenar
                if "AnoMesNum" in purchase_frequency.columns:
                    purchase_frequency["AnoMesNum"] = purchase_frequency["AnoMesNum"].astype(int)
                    purchase_frequency = purchase_frequency.sort_values("AnoMesNum")
                
                fig_freq = px.bar(purchase_frequency, x="AnoMesStr", y="Count", title="Emplacamentos ao Longo do Tempo", labels={'AnoMesStr': 'M√™s/Ano', 'Count': 'Qtd. Emplacamentos'})
                fig_freq.update_layout(xaxis_title="", yaxis_title="Quantidade")
                st.plotly_chart(fig_freq, use_container_width=True)
            else:
                st.info("Gr√°fico de frequ√™ncia n√£o dispon√≠vel (apenas uma compra registrada).")

            # An√°lise de Prefer√™ncias
            st.markdown("##### Prefer√™ncias do Cliente")
            pref_cols = st.columns(3)
            preferred_brands = get_modes(client_df["Marca"])
            preferred_segments = get_modes(client_df["Segmento"])
            preferred_models = get_modes(client_df["Modelo"])

            pref_cols[0].metric("Marca(s) Preferida(s)", format_list(preferred_brands))
            pref_cols[1].metric("Segmento(s) Preferido(s)", format_list(preferred_segments))
            pref_cols[2].metric("Modelo(s) Preferido(s)", format_list(preferred_models))

        else:
            # Isso n√£o deve acontecer se results_df n√£o estava vazio e o CNPJ foi identificado
            st.error("Erro inesperado ao filtrar os dados do cliente.")
else:
    # --- Resumo Geral (se nenhuma busca ativa) ---
    st.subheader("Resumo Geral da Base de Dados")
    st.markdown("*(Considerando os filtros aplicados na barra lateral, se houver)*")

    if df_display.empty:
        st.warning("Nenhum dado dispon√≠vel para exibir com os filtros selecionados.")
    else:
        # M√©tricas Gerais
        total_emplacamentos = len(df_display)
        total_clientes = df_display["CNPJ_NORMALIZED"].nunique()
        data_inicio = df_display["Data emplacamento"].min()
        data_fim = df_display["Data emplacamento"].max()

        col1_res, col2_res, col3_res = st.columns(3)
        col1_res.metric("Total de Emplacamentos", total_emplacamentos)
        col2_res.metric("Clientes √önicos", total_clientes)
        col3_res.metric("Per√≠odo Coberto", f"{data_inicio.strftime('%m/%Y') if pd.notna(data_inicio) else 'N/A'} a {data_fim.strftime('%m/%Y') if pd.notna(data_fim) else 'N/A'}")

        st.markdown("#### Emplacamentos por Ano")
        # Garantir que n√£o h√° NaN em Ano antes de agrupar
        emplac_por_ano = df_display.dropna(subset=["Ano"]).groupby("Ano").size().reset_index(name="Count")
        if not emplac_por_ano.empty:
            emplac_por_ano["Ano"] = emplac_por_ano["Ano"].astype(int)  # Garantir que Ano √© int
            fig_ano = px.bar(emplac_por_ano, x="Ano", y="Count", title="Total de Emplacamentos por Ano", labels={'Ano': 'Ano', 'Count': 'Quantidade'})
            fig_ano.update_layout(xaxis_type='category') # Tratar ano como categoria
            st.plotly_chart(fig_ano, use_container_width=True)
        else:
            st.info("N√£o h√° dados suficientes para gerar o gr√°fico de emplacamentos por ano.")

        st.markdown("#### Emplacamentos por Marca e Ano")
        # Garantir que n√£o h√° NaN em Ano ou Marca antes de agrupar
        emplac_marca_ano = df_display.dropna(subset=["Ano", "Marca"]).groupby(["Ano", "Marca"]).size().reset_index(name="Count")
        if not emplac_marca_ano.empty:
            emplac_marca_ano["Ano"] = emplac_marca_ano["Ano"].astype(int)  # Garantir que Ano √© int
            
            # Pivotar para formato wide
            try:
                pivot_marca_ano = emplac_marca_ano.pivot(index="Marca", columns="Ano", values="Count").fillna(0).astype(int)
                # Adicionar total por marca
                pivot_marca_ano["Total"] = pivot_marca_ano.sum(axis=1)
                # Ordenar pelo total
                pivot_marca_ano = pivot_marca_ano.sort_values("Total", ascending=False)
                st.dataframe(pivot_marca_ano, use_container_width=True)
            except Exception as pivot_error:
                st.warning(f"N√£o foi poss√≠vel gerar a tabela de emplacamentos por marca e ano: {pivot_error}")
        else:
            st.info("N√£o h√° dados suficientes para gerar a tabela de emplacamentos por marca e ano.")

# --- Rodap√© (Opcional) ---
st.sidebar.divider()
if os.path.exists(LOGO_WHITE_PATH):
    st.sidebar.image(LOGO_WHITE_PATH, width=150)
st.sidebar.markdown("¬© De Nigris Distribuidora")
